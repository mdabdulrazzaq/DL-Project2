{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":98084,"databundleVersionId":11711500,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T01:42:05.857612Z","iopub.execute_input":"2025-04-22T01:42:05.857849Z","iopub.status.idle":"2025-04-22T01:42:08.959645Z","shell.execute_reply.started":"2025-04-22T01:42:05.857823Z","shell.execute_reply":"2025-04-22T01:42:08.958919Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -----------------------------\n# 1. Import libraries\n# -----------------------------\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import load_dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n# -----------------------------\n# 2. Use GPU if available\n# -----------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -----------------------------\n# 3. Load and preprocess AGNEWS dataset\n# -----------------------------\ndataset = load_dataset(\"ag_news\")\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\ntokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T01:59:31.029161Z","iopub.execute_input":"2025-04-22T01:59:31.029896Z","iopub.status.idle":"2025-04-22T01:59:34.193120Z","shell.execute_reply.started":"2025-04-22T01:59:31.029868Z","shell.execute_reply":"2025-04-22T01:59:34.192300Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ec30be853504cf29a509e0fc2d86330"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# ============================================================\n# 4. 🧠 Load RoBERTa Model with LoRA Adapters\n# ============================================================\n\nfrom transformers import RobertaForSequenceClassification\n\n# Load pre-trained RoBERTa-base model for 4-class classification\nbase_model = \"roberta-base\"\nmodel = RobertaForSequenceClassification.from_pretrained(base_model, num_labels=4)\n\n# LoRA Adapter Configuration\nlora_config = LoraConfig(\n    r=8,                                # Rank of LoRA matrices (low for parameter efficiency)\n    lora_alpha=32,                      # Scaling factor; typically 2–4× r\n    lora_dropout=0.1,                   # Slightly higher dropout helps regularize small-rank updates\n    bias=\"none\",                        # Don't adapt bias (saves params, avoids drift)\n    target_modules=[\"query\", \"value\"],  # Target core attention weights\n    task_type=TaskType.SEQ_CLS          # Sequence classification task\n)\n\n# Apply LoRA to base model\nmodel = get_peft_model(model, lora_config)\nmodel.to(device)\n\n# Show trainable parameter count for sanity check\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T02:00:14.492064Z","iopub.execute_input":"2025-04-22T02:00:14.492657Z","iopub.status.idle":"2025-04-22T02:00:14.888615Z","shell.execute_reply.started":"2025-04-22T02:00:14.492635Z","shell.execute_reply":"2025-04-22T02:00:14.887984Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 888,580 || all params: 125,537,288 || trainable%: 0.7078\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================================\n# 5. ⚙️ Training Configuration — Optimized for LoRA\n# ============================================================\n\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results_lora_agnews\",     # More descriptive output dir\n    eval_strategy=\"epoch\",            # Evaluate every epoch\n    save_strategy=\"epoch\",                  # Save once per epoch\n    save_total_limit=1,                     # Keep only the best model\n    load_best_model_at_end=True,            # Restore best weights after training\n    metric_for_best_model=\"eval_accuracy\",  # Use accuracy as the benchmark\n    greater_is_better=True,\n\n    learning_rate=2e-5,                     # Lower LR helps avoid overfitting\n    per_device_train_batch_size=8,          # Small batch size with accum steps\n    per_device_eval_batch_size=64,\n    gradient_accumulation_steps=2,          # Effective batch size = 16\n    num_train_epochs=5,                     # Sweet spot for small adapters\n\n    warmup_ratio=0.1,                       # More adaptive than fixed steps\n    weight_decay=0.01,                      # Light regularization\n\n    lr_scheduler_type=\"cosine\",             # Smooth warmup + decay\n    fp16=True,                              # Use FP16 if GPU supports it\n\n    logging_dir=\"./logs\",                   # Where to save logs\n    logging_steps=50,\n    report_to=\"none\"                        # Turn off default logging to HuggingFace hub\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T02:01:03.434208Z","iopub.execute_input":"2025-04-22T02:01:03.434790Z","iopub.status.idle":"2025-04-22T02:01:03.469180Z","shell.execute_reply.started":"2025-04-22T02:01:03.434770Z","shell.execute_reply":"2025-04-22T02:01:03.468446Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ============================================================\n# 6. 🚀 Train the Model\n# ============================================================\n\n# Define metric computation function\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc}\n\n# Initialize Trainer with model, data, tokenizer, and config\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# Start training\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlog_history = trainer.state.log_history\ntrain_loss = [x[\"loss\"] for x in log_history if \"loss\" in x]\neval_loss = [x[\"eval_loss\"] for x in log_history if \"eval_loss\" in x]\neval_accuracy = [x[\"eval_accuracy\"] for x in log_history if \"eval_accuracy\" in x]\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.figure(figsize=(10, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_loss, label='Train Loss')\nplt.plot(epochs[:len(eval_loss)], eval_loss, label='Eval Loss')\nplt.title(\"Loss per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs[:len(eval_accuracy)], eval_accuracy, marker='o', label='Eval Accuracy')\nplt.title(\"Eval Accuracy per Epoch\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport numpy as np\n\n# Evaluate model on test set without retraining\noutputs = trainer.predict(tokenized_dataset[\"test\"])\n\n# Extract predictions and true labels\npredictions = np.argmax(outputs.predictions, axis=1)\nlabels = outputs.label_ids\n\n# Calculate accuracy\nacc = accuracy_score(labels, predictions)\nprint(\"Final Evaluation Accuracy:\", acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T00:53:33.059596Z","iopub.execute_input":"2025-04-22T00:53:33.059972Z","iopub.status.idle":"2025-04-22T00:56:48.814218Z","shell.execute_reply.started":"2025-04-22T00:53:33.059945Z","shell.execute_reply":"2025-04-22T00:56:48.813503Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Final Evaluation Accuracy: 0.9527631578947369\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from datasets import Dataset\nfrom torch.utils.data import DataLoader\n\n# Load dataset object\nwith open(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\", \"rb\") as f:\n    test_dataset = pickle.load(f)\n\n# Convert to HuggingFace Dataset (already is, but this helps formatting)\ntest_dataset = Dataset.from_dict({\"text\": test_dataset[\"text\"]})\n\n# Tokenize function\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\n# Apply tokenizer\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# Create PyTorch DataLoader for batching\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=64)\n\n# Prediction loop\nmodel.eval()\nall_predictions = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_predictions.extend(preds.cpu().numpy())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# 10. Save predictions to CSV\n# -----------------------------\ndf = pd.DataFrame({\n    \"ID\": list(range(len(all_predictions))),   # ID ✅\n    \"label\": all_predictions\n})\ndf.to_csv(\"submission.csv\", index=False)\nprint(\"✅ Batched predictions complete. Saved to submission.csv.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T01:07:07.950776Z","iopub.execute_input":"2025-04-22T01:07:07.951133Z","iopub.status.idle":"2025-04-22T01:07:08.020304Z","shell.execute_reply.started":"2025-04-22T01:07:07.951102Z","shell.execute_reply":"2025-04-22T01:07:08.019338Z"}},"outputs":[{"name":"stdout","text":"✅ Batched predictions complete. Saved to submission.csv.\n","output_type":"stream"}],"execution_count":12}]}